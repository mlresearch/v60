---
title: Online Aggregation of Unbounded Signed Losses Using Shifting Experts
abstract: "For the decision theoretic online (DTOL) setting,\r we consider methods
  to construct algorithms that suffer loss not much more than of any sequence of experts\r
  distributed along a time interval (shifting experts setting).\r We present a modified
  version of the method of Mixing Past Posteriors\r which uses as basic algorithm
  AdaHedge with adaptive learning rate.\r Due to this, we combine the advantages of
  both algorithms:\r regret bounds are valid in the case of signed unbounded losses
  of the experts,\r also, we use the shifting regret which is a more optimal characteristic
  of the algorithm.\r All results are obtained in the adversarial setting—no assumptions
  are made about the nature of data source.\r We present results of numerical experiments
  for the case where losses of the experts cannot be bounded in advance."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: v’yugin17a
month: 0
tex_title: Online Aggregation of Unbounded Signed Losses Using Shifting Experts
firstpage: 3
lastpage: 17
page: 3-17
order: 3
cycles: false
author:
- given: Vladimir V.
  family: V’yugin
date: 2017-05-31
address: 
publisher: PMLR
container-title: Proceedings of the Sixth Workshop on Conformal and Probabilistic
  Prediction and Applications
volume: '60'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 5
  - 31
pdf: http://proceedings.mlr.press/v60/v’yugin17a/v’yugin17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
